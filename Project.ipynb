{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Dat550 Project"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package vader_lexicon to\n",
      "[nltk_data]     /home/magnus/nltk_data...\n",
      "[nltk_data]   Package vader_lexicon is already up-to-date!\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 104,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import json\n",
    "import string\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import nltk\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import classification_report\n",
    "from nltk.sentiment import SentimentIntensityAnalyzer\n",
    "import textstat  # pip install textstat\n",
    "from tqdm import tqdm\n",
    "tqdm.pandas()\n",
    "\n",
    "nltk.download('vader_lexicon')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "metadata": {},
   "outputs": [],
   "source": [
    "# df = pd.read_xml(\"Webis-data/extracted/ground-truth-training-byarticle-20181122.xml\")\n",
    "# df.to_json(\"preprocessing/data/ground-truth-training-byarticle.jsonl\",orient=\"records\",lines=True)\n",
    "\n",
    "# df = pd.read_xml(\"Webis-data/extracted/ground-truth-training-bypublisher-20181122.xml\")\n",
    "# df.to_json(\"preprocessing/data/ground-truth-training-bypublisher.jsonl\",orient=\"records\",lines=True)\n",
    "\n",
    "# df = pd.read_xml(\"Webis-data/extracted/ground-truth-test-bypublisher-20181212.xml\")\n",
    "# df.to_json(\"preprocessing/data/ground-truth-test-bypublisher.jsonl\",orient=\"records\",lines=True)\n",
    "\n",
    "# df = pd.read_xml(\"Webis-data/extracted/ground-truth-test-byarticle-20181207.xml\")\n",
    "# df.to_json(\"preprocessing/data/ground-truth-test-byarticle.jsonl\",orient=\"records\",lines=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "metadata": {},
   "outputs": [],
   "source": [
    "filepath = \"preprocessing/data/articles-training-bypublisher.jsonl\"\n",
    "\n",
    "def load_json(filepath):\n",
    "\n",
    "    articles = []\n",
    "    table = str.maketrans(\"\",\"\",string.punctuation+\"“”‘’\")\n",
    "\n",
    "    with open(filepath, \"r\") as f:\n",
    "        for line in f:\n",
    "            data = json.loads(line)\n",
    "            title = data[\"title\"].lower().translate(table)\n",
    "            content = data[\"content\"].lower().translate(table)\n",
    "            articles.append({\n",
    "                \"id\": int(data[\"id\"]),\n",
    "                \"content\": f\"{title} {content}\"\n",
    "            })\n",
    "    \n",
    "\n",
    "    return pd.DataFrame(articles)\n",
    "\n",
    "\n",
    "\n",
    "def load_ground_truth(filepath):\n",
    "    return pd.read_json(filepath, orient=\"records\", lines=True)\n",
    "\n",
    "def merge_with_ground_truth(articles_df, ground_truth_df):\n",
    "    return articles_df.merge(ground_truth_df[['id', 'hyperpartisan']], on='id', how='left')\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "metadata": {},
   "outputs": [],
   "source": [
    "def extract_features(text):\n",
    "    sia = SentimentIntensityAnalyzer()\n",
    "    sentiment = sia.polarity_scores(text)\n",
    "\n",
    "    features = {\n",
    "        'sent_neg': sentiment['neg'],\n",
    "        'sent_pos': sentiment['pos'],\n",
    "        'sent_compound': sentiment['compound'],\n",
    "        'flesch': textstat.flesch_reading_ease(text),\n",
    "        'smog': textstat.smog_index(text),\n",
    "        'exclam': text.count('!'),\n",
    "        'questions': text.count('?'),\n",
    "        'quotes': text.count('\"'),\n",
    "        'length': len(text.split())\n",
    "    }\n",
    "\n",
    "    partisan_terms = {\n",
    "        'far_left': ['socialist', 'progressive', 'woke'],\n",
    "        'far_right': ['maga', 'conservative', 'patriot']\n",
    "    }\n",
    "\n",
    "    for group, terms in partisan_terms.items():\n",
    "        features[f'count_{group}'] = sum(text.count(term) for term in terms)\n",
    "\n",
    "    return features\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "metadata": {},
   "outputs": [],
   "source": [
    "def prepare_data(article_path, truth_path):\n",
    "    print(\"Loading and merging data...\")\n",
    "    articles_df = load_json(article_path)\n",
    "    ground_truth_df = load_ground_truth(truth_path)\n",
    "    df = merge_with_ground_truth(articles_df, ground_truth_df)\n",
    "\n",
    "    # Filter out samples with missing labels\n",
    "    df = df.dropna(subset=['hyperpartisan'])\n",
    "    df['label'] = df['hyperpartisan'].astype(int)\n",
    "    return df\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "metadata": {},
   "outputs": [],
   "source": [
    "def vectorize_text(df):\n",
    "    print(\"Vectorizing text with TF-IDF...\")\n",
    "    tfidf = TfidfVectorizer(\n",
    "        ngram_range=(1, 2),\n",
    "        stop_words='english',\n",
    "        max_features=1000,\n",
    "    )\n",
    "    X_text = tfidf.fit_transform(df['content'])\n",
    "    return X_text, tfidf\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "metadata": {},
   "outputs": [],
   "source": [
    "def extract_stylometric_features(df):\n",
    "    print(\"Extracting stylometric and sentiment features...\")\n",
    "    style_features = df['content'].progress_apply(extract_features)\n",
    "    return pd.DataFrame(style_features.tolist())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "metadata": {},
   "outputs": [],
   "source": [
    "def combine_features(X_text, X_style):\n",
    "    print(\"Combining TF-IDF and stylometric features...\")\n",
    "    \n",
    "    # Convert column names to string types\n",
    "    X_text = pd.DataFrame(X_text.toarray()).reset_index(drop=True)\n",
    "    X_style = X_style.reset_index(drop=True)\n",
    "    \n",
    "    # Ensure that all column names are strings\n",
    "    X_text.columns = X_text.columns.astype(str)\n",
    "    X_style.columns = X_style.columns.astype(str)\n",
    "    \n",
    "    # Concatenate the dataframes (TF-IDF + stylometric features)\n",
    "    X_all = pd.concat([X_text, X_style], axis=1)\n",
    "    \n",
    "    return X_all\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_and_evaluate(X_train, X_test, y_train, y_test):\n",
    "    print(\"Training Logistic Regression model...\")\n",
    "    model = LogisticRegression(\n",
    "        class_weight='balanced',\n",
    "        max_iter=1000,\n",
    "        solver='liblinear'\n",
    "    )\n",
    "    model.fit(X_train, y_train)\n",
    "\n",
    "    print(\"\\nModel Evaluation:\")\n",
    "    preds = model.predict(X_test)\n",
    "    print(classification_report(y_test, preds))\n",
    "\n",
    "    return model\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "metadata": {},
   "outputs": [],
   "source": [
    "def show_top_features(model, tfidf, X_style):\n",
    "    print(\"\\nTop Predictive Features:\")\n",
    "    feature_names = tfidf.get_feature_names_out().tolist() + X_style.columns.tolist()\n",
    "    coef_df = pd.DataFrame({\n",
    "        'feature': feature_names,\n",
    "        'coefficient': model.coef_[0]\n",
    "    }).sort_values('coefficient', key=abs, ascending=False)\n",
    "    display(coef_df.head(20))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading and merging data...\n"
     ]
    }
   ],
   "source": [
    "# Load and process articles\n",
    "df = prepare_data(\n",
    "    \"preprocessing/data/articles-training-byarticle.jsonl\",\n",
    "    \"preprocessing/data/ground-truth-training-byarticle.jsonl\"\n",
    ")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Vectorizing text with TF-IDF...\n",
      "Extracting stylometric and sentiment features...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 645/645 [00:09<00:00, 65.03it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Combining TF-IDF and stylometric features...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "X_text, tfidf = vectorize_text(df)\n",
    "X_style = extract_stylometric_features(df)\n",
    "X_train = combine_features(X_text, X_style)\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Vectorizing text with TF-IDF...\n",
      "Extracting stylometric and sentiment features...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 628/628 [00:10<00:00, 60.43it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Combining TF-IDF and stylometric features...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "test_articles_path = \"preprocessing/data/articles-test-byarticle.jsonl\"\n",
    "test_ground_truth_path = \"preprocessing/data/ground-truth-test-byarticle.jsonl\"\n",
    "\n",
    "# Load the test data and ground truth as DataFrames\n",
    "test_articles = pd.read_json(test_articles_path, orient=\"records\", lines=True)\n",
    "test_ground_truth = pd.read_json(test_ground_truth_path, orient=\"records\", lines=True)\n",
    "\n",
    "test_articles = test_articles.drop(columns=['hyperpartisan'])\n",
    "# Merge the two DataFrames\n",
    "test_data_df = pd.merge(test_articles, test_ground_truth[['id', 'hyperpartisan']], on='id')\n",
    "\n",
    "\n",
    "X_text_test, tfidf = vectorize_text(test_data_df)\n",
    "X_style_test = extract_stylometric_features(test_data_df)\n",
    "X_test = combine_features(X_text_test, X_style_test)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load pre-split data\n",
    "# Or manually split just once and save using joblib.dump()\n",
    "y_train = df[\"hyperpartisan\"].astype(int)\n",
    "y_test = test_data_df[\"hyperpartisan\"].astype(int)\n",
    "\n",
    "X_train.columns = X_train.columns.astype(str)\n",
    "X_test.columns = X_test.columns.astype(str)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Logistic Regression model...\n",
      "\n",
      "Model Evaluation:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.51      0.98      0.67       314\n",
      "           1       0.74      0.04      0.08       314\n",
      "\n",
      "    accuracy                           0.51       628\n",
      "   macro avg       0.62      0.51      0.38       628\n",
      "weighted avg       0.62      0.51      0.38       628\n",
      "\n",
      "\n",
      "Top Predictive Features:\n"
     ]
    },
    {
     "data": {
      "application/vnd.microsoft.datawrangler.viewer.v0+json": {
       "columns": [
        {
         "name": "index",
         "rawType": "int64",
         "type": "integer"
        },
        {
         "name": "feature",
         "rawType": "object",
         "type": "string"
        },
        {
         "name": "coefficient",
         "rawType": "float64",
         "type": "float"
        }
       ],
       "conversionMethod": "pd.DataFrame",
       "ref": "4733789b-8ff7-4106-92f8-d80ed686d846",
       "rows": [
        [
         "827",
         "staff",
         "1.5708026169462062"
        ],
        [
         "904",
         "trump said",
         "1.5083878737206784"
        ],
        [
         "391",
         "high",
         "1.4731980498034065"
        ],
        [
         "762",
         "russia",
         "-1.4111740096543894"
        ],
        [
         "658",
         "playing",
         "-1.2853648717724693"
        ],
        [
         "678",
         "president",
         "1.2206950049306975"
        ],
        [
         "977",
         "women",
         "1.1660323528874186"
        ],
        [
         "55",
         "american people",
         "1.12604171873614"
        ],
        [
         "54",
         "american",
         "1.075762915814751"
        ],
        [
         "662",
         "policy",
         "1.0449657783284385"
        ],
        [
         "1001",
         "sent_pos",
         "1.00889929363768"
        ],
        [
         "237",
         "democratic",
         "0.9880210034370739"
        ],
        [
         "438",
         "islam",
         "-0.9845614490805572"
        ],
        [
         "82",
         "author",
         "-0.9095612298401681"
        ],
        [
         "704",
         "putin",
         "0.8515139125443659"
        ],
        [
         "394",
         "hillary clinton",
         "0.8483615112043406"
        ],
        [
         "908",
         "trying",
         "0.8177409203012271"
        ],
        [
         "918",
         "understand",
         "-0.8124869607608477"
        ],
        [
         "1000",
         "sent_neg",
         "0.8103310784524013"
        ],
        [
         "530",
         "make",
         "0.7812647352308106"
        ]
       ],
       "shape": {
        "columns": 2,
        "rows": 20
       }
      },
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>feature</th>\n",
       "      <th>coefficient</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>827</th>\n",
       "      <td>staff</td>\n",
       "      <td>1.570803</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>904</th>\n",
       "      <td>trump said</td>\n",
       "      <td>1.508388</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>391</th>\n",
       "      <td>high</td>\n",
       "      <td>1.473198</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>762</th>\n",
       "      <td>russia</td>\n",
       "      <td>-1.411174</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>658</th>\n",
       "      <td>playing</td>\n",
       "      <td>-1.285365</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>678</th>\n",
       "      <td>president</td>\n",
       "      <td>1.220695</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>977</th>\n",
       "      <td>women</td>\n",
       "      <td>1.166032</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>55</th>\n",
       "      <td>american people</td>\n",
       "      <td>1.126042</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>54</th>\n",
       "      <td>american</td>\n",
       "      <td>1.075763</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>662</th>\n",
       "      <td>policy</td>\n",
       "      <td>1.044966</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1001</th>\n",
       "      <td>sent_pos</td>\n",
       "      <td>1.008899</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>237</th>\n",
       "      <td>democratic</td>\n",
       "      <td>0.988021</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>438</th>\n",
       "      <td>islam</td>\n",
       "      <td>-0.984561</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>82</th>\n",
       "      <td>author</td>\n",
       "      <td>-0.909561</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>704</th>\n",
       "      <td>putin</td>\n",
       "      <td>0.851514</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>394</th>\n",
       "      <td>hillary clinton</td>\n",
       "      <td>0.848362</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>908</th>\n",
       "      <td>trying</td>\n",
       "      <td>0.817741</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>918</th>\n",
       "      <td>understand</td>\n",
       "      <td>-0.812487</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1000</th>\n",
       "      <td>sent_neg</td>\n",
       "      <td>0.810331</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>530</th>\n",
       "      <td>make</td>\n",
       "      <td>0.781265</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "              feature  coefficient\n",
       "827             staff     1.570803\n",
       "904        trump said     1.508388\n",
       "391              high     1.473198\n",
       "762            russia    -1.411174\n",
       "658           playing    -1.285365\n",
       "678         president     1.220695\n",
       "977             women     1.166032\n",
       "55    american people     1.126042\n",
       "54           american     1.075763\n",
       "662            policy     1.044966\n",
       "1001         sent_pos     1.008899\n",
       "237        democratic     0.988021\n",
       "438             islam    -0.984561\n",
       "82             author    -0.909561\n",
       "704             putin     0.851514\n",
       "394   hillary clinton     0.848362\n",
       "908            trying     0.817741\n",
       "918        understand    -0.812487\n",
       "1000         sent_neg     0.810331\n",
       "530              make     0.781265"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Train & evaluate\n",
    "model = train_and_evaluate(X_train, X_test, y_train, y_test)\n",
    "show_top_features(model, tfidf, X_style)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 119,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of misclassified samples: 305\n"
     ]
    }
   ],
   "source": [
    "\n",
    "misclassified = X_test[y_test != model.predict(X_test)]\n",
    "print(\"Number of misclassified samples:\", misclassified.shape[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 120,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Combining TF-IDF and stylometric features...\n",
      "Prediction: Not Hyperpartisan (Confidence: 0.84)\n"
     ]
    }
   ],
   "source": [
    "def predict_single_article(article_text, tfidf, model, X_style_columns):\n",
    "    # Vectorize the text\n",
    "    X_text = tfidf.transform([article_text])\n",
    "\n",
    "    # Extract stylometric features\n",
    "    style_features = extract_features(article_text)\n",
    "    X_style = pd.DataFrame([style_features])\n",
    "\n",
    "    # Ensure correct column order (in case some features were missing)\n",
    "    X_style = X_style.reindex(columns=X_style_columns, fill_value=0)\n",
    "\n",
    "    # Combine features\n",
    "    X_all = combine_features(X_text, X_style)\n",
    "\n",
    "    # Predict\n",
    "    prediction = model.predict(X_all)[0]\n",
    "    confidence = model.predict_proba(X_all)[0].max()\n",
    "    return prediction, confidence\n",
    "\n",
    "\n",
    "# Save stylometric feature columns from training to keep consistent\n",
    "X_style_columns = X_style.columns\n",
    "\n",
    "# Predict the third article (index 2) content from test_articles\n",
    "article_text = test_articles[\"content\"].iloc[2]\n",
    "\n",
    "# Predict\n",
    "pred, conf = predict_single_article(article_text, tfidf, model, X_style_columns)\n",
    "\n",
    "print(f\"Prediction: {'Hyperpartisan' if pred == 1 else 'Not Hyperpartisan'} (Confidence: {conf:.2f})\")\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
