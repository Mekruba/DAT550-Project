{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Dat550 Project"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "import string\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import classification_report\n",
    "from nltk.sentiment import SentimentIntensityAnalyzer\n",
    "import textstat  # pip install textstat\n",
    "from tqdm.notebook import tqdm  # Better for notebooks\n",
    "tqdm.pandas()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# df = pd.read_xml(\"Webis-data/extracted/ground-truth-training-byarticle-20181122.xml\")\n",
    "# df.to_json(\"preprocessing/data/ground-truth-training-byarticle.jsonl\",orient=\"records\",lines=True)\n",
    "\n",
    "# df = pd.read_xml(\"Webis-data/extracted/ground-truth-training-bypublisher-20181122.xml\")\n",
    "# df.to_json(\"preprocessing/data/ground-truth-training-bypublisher.jsonl\",orient=\"records\",lines=True)\n",
    "\n",
    "# df = pd.read_xml(\"Webis-data/extracted/ground-truth-test-bypublisher-20181212.xml\")\n",
    "# df.to_json(\"preprocessing/data/ground-truth-test-bypublisher.jsonl\",orient=\"records\",lines=True)\n",
    "\n",
    "# df = pd.read_xml(\"Webis-data/extracted/ground-truth-test-byarticle-20181207.xml\")\n",
    "# df.to_json(\"preprocessing/data/ground-truth-test-byarticle.jsonl\",orient=\"records\",lines=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "filepath = \"preprocessing/data/articles-training-bypublisher.jsonl\"\n",
    "\n",
    "def load_json(filepath):\n",
    "\n",
    "    articles = []\n",
    "    table = str.maketrans(\"\",\"\",string.punctuation+\"“”‘’\")\n",
    "\n",
    "    with open(filepath, \"r\") as f:\n",
    "        for line in f:\n",
    "            data = json.loads(line)\n",
    "            title = data[\"title\"].lower().translate(table)\n",
    "            content = data[\"content\"].lower().translate(table)\n",
    "            articles.append({\n",
    "                \"id\": int(data[\"id\"]),\n",
    "                \"content\": f\"{title} {content}\"\n",
    "            })\n",
    "    \n",
    "\n",
    "    return pd.DataFrame(articles)\n",
    "\n",
    "\n",
    "\n",
    "def load_ground_truth(filepath):\n",
    "    return pd.read_json(filepath, orient=\"records\", lines=True)\n",
    "\n",
    "def merge_with_ground_truth(articles_df, ground_truth_df):\n",
    "    return articles_df.merge(ground_truth_df[['id', 'hyperpartisan']], on='id', how='left')\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def extract_features(text):\n",
    "    sia = SentimentIntensityAnalyzer()\n",
    "    sentiment = sia.polarity_scores(text)\n",
    "\n",
    "    features = {\n",
    "        'sent_neg': sentiment['neg'],\n",
    "        'sent_pos': sentiment['pos'],\n",
    "        'sent_compound': sentiment['compound'],\n",
    "        'flesch': textstat.flesch_reading_ease(text),\n",
    "        'smog': textstat.smog_index(text),\n",
    "        'exclam': text.count('!'),\n",
    "        'questions': text.count('?'),\n",
    "        'quotes': text.count('\"'),\n",
    "        'length': len(text.split())\n",
    "    }\n",
    "\n",
    "    partisan_terms = {\n",
    "        'far_left': ['socialist', 'progressive', 'woke'],\n",
    "        'far_right': ['maga', 'conservative', 'patriot']\n",
    "    }\n",
    "\n",
    "    for group, terms in partisan_terms.items():\n",
    "        features[f'count_{group}'] = sum(text.count(term) for term in terms)\n",
    "\n",
    "    return features\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def prepare_data(article_path, truth_path):\n",
    "    print(\"Loading and merging data...\")\n",
    "    articles_df = load_json(article_path)\n",
    "    ground_truth_df = load_ground_truth(truth_path)\n",
    "    df = merge_with_ground_truth(articles_df, ground_truth_df)\n",
    "\n",
    "    # Filter out samples with missing labels\n",
    "    df = df.dropna(subset=['hyperpartisan'])\n",
    "    df['label'] = df['hyperpartisan'].astype(int)\n",
    "    return df\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "def vectorize_text(df):\n",
    "    print(\"Vectorizing text with TF-IDF...\")\n",
    "    tfidf = TfidfVectorizer(\n",
    "        ngram_range=(1, 2),\n",
    "        stop_words='english',\n",
    "        max_features=1000,\n",
    "    )\n",
    "    X_text = tfidf.fit_transform(df['content'])\n",
    "    return X_text, tfidf\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def extract_stylometric_features(df):\n",
    "    print(\"Extracting stylometric and sentiment features...\")\n",
    "    style_features = df['content'].progress_apply(extract_features)\n",
    "    return pd.DataFrame(style_features.tolist())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def combine_features(X_text, X_style):\n",
    "    print(\"Combining TF-IDF and stylometric features...\")\n",
    "    X_all = pd.concat([\n",
    "        pd.DataFrame(X_text.toarray()).reset_index(drop=True),\n",
    "        X_style.reset_index(drop=True)\n",
    "    ], axis=1)\n",
    "    return X_all\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_and_evaluate(X_train, X_test, y_train, y_test):\n",
    "    print(\"Training Logistic Regression model...\")\n",
    "    model = LogisticRegression(\n",
    "        class_weight='balanced',\n",
    "        max_iter=1000,\n",
    "        solver='liblinear'\n",
    "    )\n",
    "    model.fit(X_train, y_train)\n",
    "\n",
    "    print(\"\\nModel Evaluation:\")\n",
    "    preds = model.predict(X_test)\n",
    "    print(classification_report(y_test, preds))\n",
    "\n",
    "    return model\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "def show_top_features(model, tfidf, X_style):\n",
    "    print(\"\\nTop Predictive Features:\")\n",
    "    feature_names = tfidf.get_feature_names_out().tolist() + X_style.columns.tolist()\n",
    "    coef_df = pd.DataFrame({\n",
    "        'feature': feature_names,\n",
    "        'coefficient': model.coef_[0]\n",
    "    }).sort_values('coefficient', key=abs, ascending=False)\n",
    "    display(coef_df.head(20))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading and merging data...\n"
     ]
    }
   ],
   "source": [
    "# Load and process articles\n",
    "df = prepare_data(\n",
    "    \"preprocessing/data/articles-training-byarticle.jsonl\",\n",
    "    \"preprocessing/data/ground-truth-training-byarticle.jsonl\"\n",
    ")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Vectorizing text with TF-IDF...\n"
     ]
    }
   ],
   "source": [
    "X_text, tfidf = vectorize_text(df)\n",
    "# X_style = extract_stylometric_features(df)\n",
    "# X_all = combine_features(X_text, X_style)\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load pre-split data\n",
    "# Or manually split just once and save using joblib.dump()\n",
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "    X_all, df['label'].values, test_size=0.3, stratify=df['label'].values, random_state=42\n",
    ")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Train & evaluate\n",
    "model = train_and_evaluate(X_train, X_test, y_train, y_test)\n",
    "show_top_features(model, tfidf, X_style)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
